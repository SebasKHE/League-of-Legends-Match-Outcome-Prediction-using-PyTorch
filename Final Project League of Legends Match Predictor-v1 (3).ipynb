{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32d60bf-0f6c-478d-8293-c2ac48f4fffc",
   "metadata": {},
   "source": [
    "### Introduction  \n",
    "\n",
    "League of Legends, a popular multiplayer online battle arena (MOBA) game, generates extensive data from matches, providing an excellent opportunity to apply machine learning techniques to real-world scenarios. Perform the following steps to build a logistic regression model aimed at predicting the outcomes of League of Legends matches.  \n",
    "\n",
    "Use the [league_of_legends_data_large.csv](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/rk7VDaPjMp1h5VXS-cUyMg/league-of-legends-data-large.csv) file to perform the tasks.  \n",
    "\n",
    "### Step 1: Data Loading and Preprocessing  \n",
    "\n",
    "#### Task 1: Load the League of Legends dataset and preprocess it for training.  \n",
    "\n",
    "Loading and preprocessing the dataset involves reading the data, splitting it into training and testing sets, and standardizing the features. You will utilize `pandas` for data manipulation, `train_test_split` from `sklearn` for data splitting, and `StandardScaler` for feature scaling.  \n",
    "\n",
    "Loading and preprocessing the dataset involves reading the data, splitting it into training and testing sets, and standardizing the features.  \n",
    "\n",
    "Please take responsibility for managing and installing all the required libraries for this lab on your own.\n",
    "\n",
    "#### Exercise 1:  \n",
    "\n",
    "Write a code to load the dataset, split it into training and testing sets, standardize the features, and convert the data into PyTorch tensors for use in training a PyTorch model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9258d50f-fd1a-4809-bc4f-01fa6ad960cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win\n",
      "1    490\n",
      "0    490\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv('league_of_legends_data_large.csv')\n",
    "df.head()\n",
    "\n",
    "\n",
    "df_a = df[df['win'] == 1]  \n",
    "df_b = df[df['win'] == 0]\n",
    "\n",
    "df_a = df_a.sample(n=490, random_state=42)\n",
    "df_b = df_b.sample(n=490, random_state=42)\n",
    "\n",
    "lol_data = pd.concat([df_a, df_b])\n",
    "\n",
    "print(lol_data['win'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kills</th>\n",
       "      <th>deaths</th>\n",
       "      <th>assists</th>\n",
       "      <th>gold_earned</th>\n",
       "      <th>cs</th>\n",
       "      <th>wards_placed</th>\n",
       "      <th>wards_killed</th>\n",
       "      <th>damage_dealt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18519</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6837</td>\n",
       "      <td>195</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>29982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>15701</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>35782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>11111</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>15674</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>43327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5887</td>\n",
       "      <td>272</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>20574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>13143</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>20663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>14961</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>30020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>16141</td>\n",
       "      <td>171</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>43367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7949</td>\n",
       "      <td>161</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>22706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     kills  deaths  assists  gold_earned   cs  wards_placed  wards_killed  \\\n",
       "951     13       9       10        18519  288             0             1   \n",
       "883      3       5        7         6837  195            14             5   \n",
       "939      3      15        9        15701  224             1             9   \n",
       "849      8       2       16        11111  152             0             1   \n",
       "703     16      17       12        15674  150             7             4   \n",
       "..     ...     ...      ...          ...  ...           ...           ...   \n",
       "211      4      12        0         5887  272            18             0   \n",
       "554      5       7        7        13143   75            12             7   \n",
       "731      3       4       16        14961  289             4             6   \n",
       "886     12      12        0        16141  171             7             2   \n",
       "203      5       8        3         7949  161            17             0   \n",
       "\n",
       "     damage_dealt  \n",
       "951          9581  \n",
       "883         29982  \n",
       "939         35782  \n",
       "849         46034  \n",
       "703         43327  \n",
       "..            ...  \n",
       "211         20574  \n",
       "554         20663  \n",
       "731         30020  \n",
       "886         43367  \n",
       "203         22706  \n",
       "\n",
       "[980 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "951    1\n",
       "883    1\n",
       "939    1\n",
       "849    1\n",
       "703    1\n",
       "      ..\n",
       "211    0\n",
       "554    0\n",
       "731    0\n",
       "886    0\n",
       "203    0\n",
       "Name: win, Length: 980, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "X = lol_data.drop('win', axis=1)\n",
    "y = lol_data['win']\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train shape: (784, 8)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_train shape: (784,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_test shape: (196, 8)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_test shape: (196,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "display(f'X_train shape: {X_train.shape}')\n",
    "display(f'y_train shape: {y_train.shape}')\n",
    "display(f'X_test shape: {X_test.shape}')\n",
    "display(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#Standarize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Conert to torch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and test sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89358ba2-8c4f-49ca-8292-16608ed8eb44",
   "metadata": {},
   "source": [
    "### Step 2: Logistic Regression Model  \n",
    "\n",
    "#### Task 2: Implement a logistic regression model using PyTorch.  \n",
    "\n",
    "Defining the logistic regression model involves specifying the input dimensions, the forward pass using the sigmoid activation function, and initializing the model, loss function, and optimizer.  \n",
    "\n",
    "#### Exercise 2:  \n",
    "\n",
    "Define the logistic regression model using PyTorch, specifying the input dimensions and the forward pass. Initialize the model, loss function, and optimizer.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da70403-14a5-4662-a490-7b678d59878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationNet(\n",
      "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, input_units=8, hidden_units=64, output_units=2):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_units, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, output_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = ClassificationNet(input_units=8, hidden_units=64, output_units=2)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-2.3484e-01,  3.4748e-01, -3.2113e-01, -1.2305e-01,  1.4403e+00,\n",
       "                        6.2436e-01, -5.6896e-01, -8.6792e-01],\n",
       "                      [-2.7924e-01,  2.7320e-01,  5.3220e-01, -2.3585e-01, -5.3234e-01,\n",
       "                       -1.4043e-01, -4.6945e-01, -1.6577e+00],\n",
       "                      [-4.2963e-03, -4.0386e-04,  3.5370e-03, -4.2044e-03, -4.9555e-04,\n",
       "                        7.9795e-03, -2.8426e-03,  1.7874e-03],\n",
       "                      [ 6.8505e-02,  1.0778e-01,  5.2125e-02, -3.2631e-03,  1.1458e-02,\n",
       "                       -1.7250e-02, -7.1964e-02,  5.1702e-03],\n",
       "                      [ 3.2246e-01,  4.5437e-02,  1.5741e-01,  4.6528e-01,  6.2364e-01,\n",
       "                       -1.6985e-01,  1.2078e-01, -6.2823e-01],\n",
       "                      [ 1.3254e-02, -1.5438e-02,  3.2413e-02, -1.1150e-02,  1.2209e-02,\n",
       "                        1.0408e-02, -1.7766e-02,  1.3521e-02],\n",
       "                      [ 1.4288e-03, -1.1746e-03,  5.5760e-04, -3.0861e-03,  3.3363e-03,\n",
       "                       -3.4286e-04, -3.0215e-04, -1.1631e-03],\n",
       "                      [-2.7571e-04, -2.0207e-04,  2.9925e-04,  3.2655e-05,  2.4760e-04,\n",
       "                       -1.1258e-04,  1.3865e-04,  1.2806e-04],\n",
       "                      [-1.0029e+00,  3.0641e-01, -4.9218e-01, -3.5866e-01,  2.8159e-02,\n",
       "                        7.1874e-01, -6.3770e-01, -1.8303e-01],\n",
       "                      [ 1.4907e-01,  5.1101e-01, -2.1911e-01, -7.3845e-02,  1.3409e+00,\n",
       "                        1.9471e-02, -7.8703e-01, -1.7809e+00],\n",
       "                      [-2.7771e-03,  1.9674e-03,  2.2682e-03,  2.0084e-03, -2.7199e-04,\n",
       "                       -4.3528e-04, -1.6600e-03, -3.4950e-03],\n",
       "                      [-2.3600e-06,  2.3492e-06, -1.1104e-05,  1.1776e-06,  2.0639e-06,\n",
       "                        6.2707e-06,  4.6346e-06,  2.2484e-06],\n",
       "                      [-5.1265e-03, -1.7115e-03,  1.2357e-02, -2.3797e-02,  1.3896e-02,\n",
       "                        2.7503e-02, -1.1425e-02,  1.1537e-02],\n",
       "                      [-2.7240e-01,  8.4133e-02,  9.1886e-02, -2.2744e-01, -5.6859e-02,\n",
       "                       -1.9523e-02, -2.9598e-01, -2.0956e-02],\n",
       "                      [-7.4633e-01, -2.3280e-01,  5.2675e-01, -5.5872e-01, -7.6217e-01,\n",
       "                       -1.8087e-03, -6.0353e-01, -7.1725e-01],\n",
       "                      [-3.1392e-02, -1.0838e-02,  4.4952e-02, -7.6327e-02, -2.4405e-02,\n",
       "                        2.3947e-02, -7.3627e-02, -7.7264e-02],\n",
       "                      [ 1.0410e-02, -1.8488e-01,  1.0758e-01, -1.0243e-01,  1.7417e-01,\n",
       "                        3.6150e-01, -1.1506e-01,  4.5083e-03],\n",
       "                      [ 4.0720e-04, -1.2409e-04, -3.7295e-05,  5.9840e-05,  3.6767e-04,\n",
       "                       -1.3456e-04,  9.9995e-05, -6.9197e-04],\n",
       "                      [-1.1932e-02,  3.0722e-02,  2.0797e-02, -3.4602e-03, -1.5066e-03,\n",
       "                        1.4045e-02, -2.0702e-02, -5.4852e-02],\n",
       "                      [ 1.5219e-04,  3.5263e-03,  1.8849e-03,  2.5450e-03,  8.6304e-03,\n",
       "                       -5.1433e-03, -7.0464e-03,  2.1495e-03],\n",
       "                      [ 1.5776e-04,  1.6968e-04,  8.4507e-05,  2.1040e-04,  1.8848e-04,\n",
       "                       -8.6020e-05, -5.1074e-05, -7.2179e-05],\n",
       "                      [-3.0881e-02, -1.2330e-03,  4.6886e-02,  4.6994e-02, -1.1016e-02,\n",
       "                       -3.4636e-02,  1.4568e-02,  3.3899e-02],\n",
       "                      [ 6.6877e-04,  1.2907e-02, -1.3453e-02, -2.7400e-02,  4.8144e-02,\n",
       "                        3.4539e-03, -2.9948e-02, -5.2327e-02],\n",
       "                      [-4.9750e-01,  2.6897e-02,  7.5484e-02, -3.3020e-01, -4.6151e-01,\n",
       "                       -5.1585e-01,  1.2956e-01, -2.8387e-01],\n",
       "                      [ 1.0636e-02, -1.2334e-03, -3.6888e-04,  1.8399e-03,  9.9668e-03,\n",
       "                        9.9929e-04,  3.6748e-03, -4.1114e-03],\n",
       "                      [ 2.4101e-04, -7.8530e-04,  1.3995e-04,  1.2623e-03,  8.0556e-04,\n",
       "                        4.7322e-04,  2.6033e-04, -1.2151e-03],\n",
       "                      [ 8.8272e-01, -5.9856e-01, -8.7721e-01, -1.3732e+00,  4.3903e-01,\n",
       "                        1.1643e+00, -6.7869e-02, -2.3723e-01],\n",
       "                      [-6.7817e-04,  1.0513e-02, -1.4763e-03,  1.9435e-03,  1.8412e-02,\n",
       "                       -1.4454e-03, -4.8740e-03,  1.6432e-02],\n",
       "                      [-5.0448e-03,  6.6690e-03, -7.0256e-03,  4.3430e-03,  1.5822e-02,\n",
       "                        4.6740e-03,  6.9265e-03,  7.2824e-03],\n",
       "                      [ 7.5853e-06, -9.0229e-07,  9.7858e-06, -3.4748e-06,  3.7586e-06,\n",
       "                        4.3263e-06,  1.4262e-06,  4.6008e-06],\n",
       "                      [-1.6726e-01,  3.4751e-01,  2.0580e-01, -1.9306e-01,  1.7718e-01,\n",
       "                        7.6690e-02, -4.3604e-01,  5.4632e-02],\n",
       "                      [-3.9813e-02,  8.7662e-03, -1.6250e-02,  3.7315e-03,  4.4946e-02,\n",
       "                        5.9213e-02, -1.2613e-02, -1.7433e-02],\n",
       "                      [-8.7128e-01, -2.5336e+00,  1.7858e+00, -1.3389e+00, -1.4804e+00,\n",
       "                        1.9269e+00, -1.0065e+00, -2.1993e+00],\n",
       "                      [-2.0057e-01, -1.0113e-01,  1.9765e-01, -2.8837e-01, -9.2317e-02,\n",
       "                        1.2321e-01,  4.2817e-02, -2.3870e-01],\n",
       "                      [-3.2610e-02, -2.3966e-01,  2.5264e-01, -4.9736e-03, -9.6366e-02,\n",
       "                        1.3475e-01, -1.4778e-01, -2.5361e-01],\n",
       "                      [ 2.4612e-02,  6.5080e-03,  4.7688e-02, -6.0204e-03,  7.1959e-03,\n",
       "                        9.3605e-03, -4.2656e-03, -2.8094e-03],\n",
       "                      [ 1.0354e-02, -1.7415e-02,  7.0726e-02, -8.9350e-03,  3.5069e-03,\n",
       "                       -2.9583e-02, -3.1966e-02, -3.9929e-02],\n",
       "                      [-9.8249e-02,  2.0367e-02,  1.7726e-01, -1.1974e-01, -1.6831e-01,\n",
       "                       -1.2345e-01, -2.5570e-02, -3.2595e-01],\n",
       "                      [-1.3209e-02,  1.6620e-02,  1.1696e-04, -2.5204e-02, -1.2548e-02,\n",
       "                        3.2428e-03, -7.1801e-03,  1.5904e-02],\n",
       "                      [-3.4713e-02, -3.0259e-02,  3.2235e-02, -2.7995e-02,  8.5002e-03,\n",
       "                       -2.2687e-02, -1.3821e-02,  2.6517e-03],\n",
       "                      [-2.4409e-02, -3.3302e-02,  4.4349e-02,  2.1033e-02,  8.6919e-02,\n",
       "                       -5.1617e-02, -5.1825e-02,  1.5427e-02],\n",
       "                      [-2.1384e-02,  3.3544e-02, -4.9552e-02, -3.5632e-02,  1.0828e-01,\n",
       "                        2.3948e-02, -4.3230e-02, -8.1826e-02],\n",
       "                      [ 2.8713e+00, -2.6643e+00, -1.3042e+00,  1.0869e+00,  1.9591e+00,\n",
       "                        1.8909e+00, -4.0343e-01, -2.2190e+00],\n",
       "                      [ 2.1110e-01,  2.2518e-01,  1.0136e-01, -1.3996e-02,  3.9880e-01,\n",
       "                        1.6797e-01,  1.9601e-01, -2.1632e-01],\n",
       "                      [-2.6035e-01,  1.1890e-01,  1.5782e-01, -4.3635e-01, -4.2387e-01,\n",
       "                        5.4107e-02, -4.1099e-01, -5.3554e-01],\n",
       "                      [-4.8056e-06, -4.7357e-05, -7.0027e-06,  2.4221e-05,  5.8318e-05,\n",
       "                        5.2815e-05, -8.5689e-07,  5.2151e-06],\n",
       "                      [-7.3997e-05, -2.0026e-05,  1.7557e-04, -1.3455e-05, -2.2611e-05,\n",
       "                       -1.6992e-04,  2.1450e-04, -1.1046e-04],\n",
       "                      [-1.2446e-03, -5.3950e-05,  3.2518e-03, -3.2929e-03, -2.7515e-03,\n",
       "                        4.3326e-03, -3.1115e-03, -2.9947e-03],\n",
       "                      [-9.3313e-01, -1.3885e-02,  6.4328e-01, -4.5959e-01, -4.7702e-01,\n",
       "                        4.1926e-02, -5.2692e-01,  2.8476e-01],\n",
       "                      [ 5.1772e-03,  1.1789e-02,  5.1769e-03,  2.9038e-03,  4.3832e-03,\n",
       "                       -8.8993e-03, -6.2771e-03,  7.5556e-03],\n",
       "                      [ 1.7548e-03,  7.6293e-04,  7.8581e-03, -1.5494e-02,  8.0067e-03,\n",
       "                        6.7983e-03, -2.7247e-03, -3.6621e-03],\n",
       "                      [ 3.4876e-05,  9.7226e-06,  5.6313e-05, -6.1905e-05,  9.3961e-05,\n",
       "                        5.4003e-05, -1.7044e-05, -3.5322e-05],\n",
       "                      [ 2.6055e-03,  1.0089e-03,  4.7772e-03, -9.5710e-04, -9.4480e-04,\n",
       "                        4.8889e-03, -1.7227e-03, -2.1792e-03],\n",
       "                      [-2.4161e-02,  8.4081e-02, -8.6479e-02, -1.0472e-01,  1.7785e-01,\n",
       "                       -5.6564e-03, -1.6636e-02, -1.0615e-01],\n",
       "                      [ 3.3660e-02, -9.0510e-03,  2.1224e-02,  6.6638e-03,  4.8324e-03,\n",
       "                        2.5702e-02, -2.4251e-03, -1.0571e-02],\n",
       "                      [-8.0607e-03,  3.3431e-02,  2.3426e-02,  5.6217e-03,  1.7585e-02,\n",
       "                        6.3454e-02, -4.9389e-02, -4.4163e-03],\n",
       "                      [-7.1208e-01,  3.7051e-01,  2.2786e-01, -8.2207e-01, -6.1111e-01,\n",
       "                       -4.4325e-01, -3.2074e-01,  6.7317e-01],\n",
       "                      [ 8.6952e-03,  4.2309e-03, -8.6860e-03,  1.3140e-02,  2.1920e-02,\n",
       "                        8.5717e-03, -3.5435e-03, -2.6215e-02],\n",
       "                      [-1.7048e+00, -1.6730e-01,  1.4229e+00,  1.1900e+00, -1.4791e-01,\n",
       "                       -1.3480e+00, -7.5475e-01, -1.9692e+00],\n",
       "                      [-2.8045e-02, -8.4027e-04,  7.7364e-03, -2.7482e-02, -9.3788e-03,\n",
       "                       -2.6277e-03, -2.2121e-02,  8.2001e-03],\n",
       "                      [-7.6912e-01, -4.1360e-01,  3.0638e-01, -8.6715e-01, -9.0612e-02,\n",
       "                       -1.4740e-01, -6.7489e-01,  2.4923e-01],\n",
       "                      [ 5.4529e-01,  1.0117e+00,  1.3824e+00, -3.0844e-01,  1.0991e+00,\n",
       "                       -3.9415e-01, -9.1645e-01,  1.7840e-01],\n",
       "                      [-5.1913e-01,  3.7252e-01, -2.2066e-02, -1.0682e-01, -3.6991e-03,\n",
       "                       -2.9420e-02,  1.9576e-01, -8.2379e-02],\n",
       "                      [ 6.3654e-02,  9.0021e-02,  3.5708e-01, -1.9450e-01,  4.0761e-01,\n",
       "                        2.1559e-01, -3.7433e-01,  4.8637e-02]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-1.7231e+00, -1.5965e+00, -1.4512e-02, -5.5871e-02, -1.1157e-01,\n",
       "                      -1.1662e-01, -3.9007e-03, -4.0784e-04, -1.9271e+00, -9.7441e-01,\n",
       "                      -4.0414e-03, -6.1365e-06, -2.9615e-02, -5.1518e-01, -2.3286e+00,\n",
       "                      -1.5300e-01, -5.6489e-01, -9.4810e-05, -7.3919e-02, -4.2969e-03,\n",
       "                      -3.0624e-04, -2.5123e-02, -5.5270e-02, -3.3419e-01, -6.7334e-03,\n",
       "                      -5.1417e-03, -2.6433e+00, -1.0669e-02, -2.6982e-02,  3.6426e-06,\n",
       "                       3.1371e-01, -8.5727e-02, -5.6119e+00, -5.0377e-01, -2.9051e-01,\n",
       "                      -2.5102e-02, -1.3141e-01, -2.4885e-01, -3.0158e-02, -4.1239e-03,\n",
       "                      -1.7119e-01, -1.2039e-01, -1.9179e+00, -1.1653e+00, -1.1737e+00,\n",
       "                      -1.3686e-04, -5.0243e-04, -3.0579e-03, -9.9512e-01, -1.4201e-02,\n",
       "                      -3.6319e-02, -6.4191e-05, -4.0573e-03, -3.2035e-01, -6.3561e-02,\n",
       "                      -3.5884e-03, -1.1466e+00,  1.9252e-03, -2.1889e+00, -5.1272e-02,\n",
       "                      -9.7150e-01, -4.1462e+00, -9.6845e-01, -1.2044e+00])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-9.5866e-02,  1.8066e-01, -4.7102e-03,  3.0170e-02,  1.1462e-01,\n",
       "                       -1.1465e-02, -4.3389e-05,  4.5102e-05, -1.5008e+00,  1.7805e-01,\n",
       "                        1.7139e-03,  1.0297e-05, -1.4919e-02, -3.3605e-01,  4.3129e-01,\n",
       "                       -2.3972e-02, -2.9040e-02,  1.0033e-04,  4.4909e-04,  4.8672e-04,\n",
       "                        3.6734e-06,  2.7524e-02,  1.5397e-03,  2.7350e-01, -3.0091e-03,\n",
       "                       -2.0955e-03, -2.1247e+00,  3.3793e-03, -3.6079e-03,  3.4820e-06,\n",
       "                        2.6207e-01,  2.4620e-02, -9.6778e-01,  3.2042e-02,  1.9636e-02,\n",
       "                       -3.7360e-03,  3.5294e-02,  5.9580e-02, -1.6409e-02,  1.5572e-02,\n",
       "                       -1.1756e-01,  2.5395e-02, -2.9740e-01, -9.2170e-01, -8.3122e-02,\n",
       "                       -3.0574e-05, -1.0882e-04, -2.1197e-03, -5.3742e-01, -1.2984e-04,\n",
       "                       -2.5670e-02, -3.0972e-05, -2.7267e-03, -6.1559e-02, -2.3096e-02,\n",
       "                        1.3463e-02, -3.5899e-01,  9.0903e-03,  1.2681e+00, -2.2178e-02,\n",
       "                       -1.1173e-01, -1.3803e+00,  8.4360e-01, -2.5321e-01],\n",
       "                      [ 9.5866e-02, -1.8066e-01,  4.7102e-03, -3.0170e-02, -1.1462e-01,\n",
       "                        1.1465e-02,  4.3389e-05, -4.5102e-05,  1.5008e+00, -1.7805e-01,\n",
       "                       -1.7139e-03, -1.0297e-05,  1.4919e-02,  3.3605e-01, -4.3129e-01,\n",
       "                        2.3972e-02,  2.9040e-02, -1.0033e-04, -4.4909e-04, -4.8673e-04,\n",
       "                       -3.6734e-06, -2.7524e-02, -1.5397e-03, -2.7350e-01,  3.0091e-03,\n",
       "                        2.0955e-03,  2.1247e+00, -3.3793e-03,  3.6079e-03, -3.4820e-06,\n",
       "                       -2.6207e-01, -2.4620e-02,  9.6778e-01, -3.2042e-02, -1.9636e-02,\n",
       "                        3.7360e-03, -3.5294e-02, -5.9580e-02,  1.6409e-02, -1.5572e-02,\n",
       "                        1.1756e-01, -2.5394e-02,  2.9740e-01,  9.2170e-01,  8.3122e-02,\n",
       "                        3.0574e-05,  1.0882e-04,  2.1197e-03,  5.3742e-01,  1.2984e-04,\n",
       "                        2.5670e-02,  3.0972e-05,  2.7267e-03,  6.1559e-02,  2.3096e-02,\n",
       "                       -1.3463e-02,  3.5899e-01, -9.0903e-03, -1.2681e+00,  2.2178e-02,\n",
       "                        1.1173e-01,  1.3803e+00, -8.4360e-01,  2.5321e-01]])),\n",
       "             ('fc2.bias', tensor([-0.1204,  0.1204]))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceaff7a-c551-4ffe-84d1-ebfe78f42058",
   "metadata": {},
   "source": [
    "### Step 3: Model Training  \n",
    "\n",
    "#### Task 3: Train the logistic regression model on the dataset.  \n",
    "\n",
    "The training loop will run for a specified number of epochs. In each epoch, the model makes predictions, calculates the loss, performs backpropagation, and updates the model parameters .  \n",
    "\n",
    "#### Exercise 3:  \n",
    "\n",
    "Write the code to train the logistic regression model on the dataset. Implement the training loop, making predictions, calculating the loss, performing backpropagation, and updating model parameters. Evaluate the model's accuracy on training and testing sets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9b0ef6-9322-4506-8d00-fa8a42061a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.7010, Test Loss: 0.7120\n",
      "Epoch [2/10], Train Loss: 0.6912, Test Loss: 0.7128\n",
      "Epoch [3/10], Train Loss: 0.6868, Test Loss: 0.7177\n",
      "Epoch [4/10], Train Loss: 0.6847, Test Loss: 0.7209\n",
      "Epoch [5/10], Train Loss: 0.6799, Test Loss: 0.7228\n",
      "Epoch [6/10], Train Loss: 0.6780, Test Loss: 0.7192\n",
      "Epoch [7/10], Train Loss: 0.6726, Test Loss: 0.7310\n",
      "Epoch [8/10], Train Loss: 0.6707, Test Loss: 0.7230\n",
      "Epoch [9/10], Train Loss: 0.6669, Test Loss: 0.7358\n",
      "Epoch [10/10], Train Loss: 0.6638, Test Loss: 0.7358\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation phase on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            test_outputs = model(X_batch)\n",
    "            loss = criterion(test_outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc00024-5c97-4443-bef8-216a6a133c2b",
   "metadata": {},
   "source": [
    "### Step 4: Model Optimization and Evaluation  \n",
    "\n",
    "#### Task 4: Implement optimization techniques and evaluate the model's performance.  \n",
    "\n",
    "Optimization techniques such as L2 regularization (Ridge Regression) help in preventing overfitting. The model is retrained with these optimizations, and its performance is evaluated on both training and testing sets.  \n",
    "\n",
    "#### Exercise 4:  \n",
    "\n",
    "Implement optimization techniques like L2 regularization and retrain the model. Evaluate the performance of the optimized model on both training and testing sets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f7ef15-0544-44c8-8907-841c7a616e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.6918, Test Loss: 0.6934\n",
      "Epoch [2/10], Train Loss: 0.6924, Test Loss: 0.6938\n",
      "Epoch [3/10], Train Loss: 0.6917, Test Loss: 0.6934\n",
      "Epoch [4/10], Train Loss: 0.6927, Test Loss: 0.6932\n",
      "Epoch [5/10], Train Loss: 0.6926, Test Loss: 0.6933\n",
      "Epoch [6/10], Train Loss: 0.6925, Test Loss: 0.6936\n",
      "Epoch [7/10], Train Loss: 0.6924, Test Loss: 0.6929\n",
      "Epoch [8/10], Train Loss: 0.6927, Test Loss: 0.6934\n",
      "Epoch [9/10], Train Loss: 0.6925, Test Loss: 0.6940\n",
      "Epoch [10/10], Train Loss: 0.6924, Test Loss: 0.6934\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay= 0.05)\n",
    "\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Store predictions and true labels for the confusion matrix\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation phase on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            test_outputs = model(X_batch)\n",
    "            loss = criterion(test_outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Convert the outputs to predicted classes\n",
    "            _, predicted_classes = torch.max(test_outputs, 1)  # Obtener la clase con la mayor probabilidad\n",
    "\n",
    "            # Almacenar las predicciones y etiquetas reales\n",
    "            if epoch == 9:\n",
    "                all_preds.extend(predicted_classes.cpu().numpy())  # Guardar las predicciones\n",
    "                all_labels.extend(y_batch.cpu().numpy())  # Guardar las etiquetas reales\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79db15b-3d10-421d-a03a-7b9de51b043e",
   "metadata": {},
   "source": [
    "### Step 5: Visualization and Interpretation  \n",
    "\n",
    "#### Task 5: Visualize the model's performance and interpret the results.  \n",
    "\n",
    "Visualization tools like confusion matrices and ROC curves provide insights into the model's performance. The confusion matrix helps in understanding the classification accuracy, while the ROC curve illustrates the trade-off between sensitivity and specificity.  \n",
    "\n",
    "#### Exercise 5:  \n",
    "\n",
    "Write code to visualize the model's performance using confusion matrices and ROC curves. Generate classification reports to evaluate precision, recall, and F1-score. Retrain the model with L2 regularization and evaluate the performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a11e4238-4636-48ca-98bc-d35f18fd485e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ad7f688290>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your code here\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0, 1])  # Si son 2 clases\n",
    "disp.plot(cmap=\"Blues\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.46      0.37      0.41        98\n",
      "     Clase 1       0.47      0.57      0.52        98\n",
      "\n",
      "    accuracy                           0.47       196\n",
      "   macro avg       0.47      0.47      0.46       196\n",
      "weighted avg       0.47      0.47      0.46       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(all_labels, all_preds, target_names=['Clase 0', 'Clase 1'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a0ca3-3b12-4b76-891b-cd918c5d2cb8",
   "metadata": {},
   "source": [
    "### Step 6: Model Saving and Loading  \n",
    "\n",
    "#### Task 6: Save and load the trained model.  \n",
    "\n",
    "This task demonstrates the techniques to persist a trained model using `torch.save` and reload it using `torch.load`. Evaluating the loaded model ensures that it retains its performance, making it practical for deployment in real-world applications.  \n",
    "\n",
    "#### Exercise 6:  \n",
    "\n",
    "Write code to save the trained model and reload it. Ensure the loaded model performs consistently by evaluating it on the test dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04cd0e68-9c5f-442c-9fca-db086adeb968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Genia\\AppData\\Local\\Temp\\ipykernel_27716\\3795384876.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassificationNet(\n",
       "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "modelo_save = torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Cargar el modelo en el mismo tipo de arquitectura\n",
    "model = ClassificationNet(input_units=8, hidden_units=64, output_units=2)  # Asegúrate de usar la misma arquitectura\n",
    "\n",
    "# Cargar los pesos\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "# Asegúrate de poner el modelo en modo de evaluación si vas a hacer inferencia\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca49bc6-c28b-4cb8-adc7-2ebe9f6ee46f",
   "metadata": {},
   "source": [
    "### Step 7: Hyperparameter Tuning  \n",
    "\n",
    "#### Task 7: Perform hyperparameter tuning to find the best learning rate.  \n",
    "\n",
    "By testing different learning rates, you will identify the optimal rate that provides the best test accuracy. This fine-tuning is crucial for enhancing model performance .  \n",
    "\n",
    "#### Exercise 7:  \n",
    "\n",
    "Perform hyperparameter tuning to find the best learning rate. Retrain the model for each learning rate and evaluate its performance to identify the optimal rate.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bd1d4d5-06b3-45ee-8a00-b3813a77ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lr 0.001, loss_trainin 0.6916  Test Loss: 0.6944\n",
      "Lr 0.01, loss_trainin 0.6970  Test Loss: 0.6952\n",
      "Lr 0.1, loss_trainin 0.9841  Test Loss: 0.9260\n",
      "Lr 0.2, loss_trainin 1.9816  Test Loss: 2.2422\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "lr_list = [0.001, 0.01, 0.1, 0.2]\n",
    "\n",
    "for lr in lr_list:\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay= 0.05)\n",
    "\n",
    "    epochs = 10\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Store predictions and true labels for the confusion matrix\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluation phase on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                test_outputs = model(X_batch)\n",
    "                loss = criterion(test_outputs, y_batch)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Convert the outputs to predicted classes\n",
    "                _, predicted_classes = torch.max(test_outputs, 1)  # Obtener la clase con la mayor probabilidad\n",
    "\n",
    "                # Almacenar las predicciones y etiquetas reales\n",
    "                if epoch == 9:\n",
    "                    all_preds.extend(predicted_classes.cpu().numpy())  # Guardar las predicciones\n",
    "                    all_labels.extend(y_batch.cpu().numpy())  # Guardar las etiquetas reales\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "    print(f'Lr {lr}, loss_trainin {train_loss:.4f}  Test Loss: {test_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252e084-8b48-4ded-80b9-e672efe412c2",
   "metadata": {},
   "source": [
    "### Step 8: Feature Importance  \n",
    "\n",
    "#### Task 8: Evaluate feature importance to understand the impact of each feature on the prediction.  \n",
    "\n",
    "The code to evaluate feature importance to understand the impact of each feature on the prediction.  \n",
    "\n",
    "#### Exercise 8:  \n",
    "\n",
    "Evaluate feature importance by extracting the weights of the linear layer and creating a DataFrame to display the importance of each feature. Visualize the feature importance using a bar plot.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bc0995c-6f00-4e38-974f-3d54058b1055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prompt: Evaluate feature importance by extracting the weights of the linear layer and creating a DataFrame to display the importance of each feature. Visualize the feature importance using a bar plot.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract feature importances from the linear layer\n",
    "weights = model.fc1.weight.detach().cpu().numpy()\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': range(weights.shape[1]), 'Importance': np.abs(weights).mean(axis=0)})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "01dcfd9092213617d1f8aeba91d73aabc8cdce47cb7efe1510845fc98189c2a4"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
